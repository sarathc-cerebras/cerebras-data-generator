models_to_run:
  - name: "qwen-3-32b"
    concurrency:
      max_concurrent_requests: 30
      min_concurrent_requests: 10
      recover_threshold: 10 # Number of fast requests before increasing concurrency
  - name: "qwen-3-235b-a22b-instruct-2507"
    concurrency:
      max_concurrent_requests: 40
      min_concurrent_requests: 10
      recover_threshold: 10
  - name: "qwen-3-235b-a22b-thinking-2507" 
    concurrency:
      max_concurrent_requests: 12
      min_concurrent_requests: 6
      recover_threshold: 10
  - name: "qwen-3-coder-480b"
    concurrency:
      max_concurrent_requests: 20
      min_concurrent_requests: 5
      recover_threshold: 10
  - name: "gpt-oss-120b" 
    concurrency:
      max_concurrent_requests: 135
      min_concurrent_requests: 30
      recover_threshold: 10

# Global settings used as fallbacks or for shared logic
concurrency:
  initial_retry_delay: 1.0
  max_retry_delay: 60.0
  max_retries: 5

# Load Monitoring
load_monitoring:
  ttft_threshold: 5.0
  request_timeout: 120.0

# API Server Settings
api_server:
  host: "0.0.0.0"
  port: 8000
  result_timeout_seconds: 300

# --- SQLite for Persistent Queue ---
database:
  path: "data/queue.db" # Path to the SQLite database file
  
generation:
  stream: true
  max_completion_tokens: 8196
  temperature: 0.7
  top_p: 0.8
  seed: 1

# Input and Output files
dataset:
  repo_type: hf
  output: "data/output/baai_infinity_instruct_core_generated.jsonl"
  #n_samples: 1
  hf:
    repo: "BAAI/Infinity-Instruct"
    subset: "7M"
    split: "train"
    num_proc: 90
    streaming: false
  local:
    format: "parquet"
    data_files: "../data/input/gsm8k_test.parquet"
    split: "test"